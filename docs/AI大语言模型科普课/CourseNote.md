# AI大语言模型科普课
### Level: Beginner
### Duration: 1 Hour
### Author: Lin Lili
### Link: [Youtube](https://youtube.com/playlist?list=PL5y2P1AqpsZ-eD0uitRVWRybSX0DZdWNG&si=G5APkZ64QoGcI5hj)
---

## Course Notes:
### AIGC and Generative AI
- AIGC: AI Generated Content. AI生成内容。
- Generative AI: 生成式AI
- The content which is generated by AI is called AIGC. and Generative AI create lots of content now.


### The relations of AI
- AI: 
  - Artificial Intelligence.
  - 人工智能，让计算机系统模拟人类的智能，从而解决问题完成任务。
- ML:
  - Machine Learning.
  - 机器学习，是AI的一个子集。
  - 核心：不需要人类显示编程。只需要通过算法让计算机自行学习和改进，去识别模式，做出预测和决策。
  - 分支：监督学习，无监督学习，强化学习。
    - Supervised Learning: 监督学习
      - 机器学习算法接收有标签的训练数据。
      - 标签：期望的输出值。
      - 训练数据结构：每个训练数据点包括输入特征和期望输出值。
      - 目标：学习输入和输出之间的映射关系，在给定新的输入输出关系时，能够准确输出相应的输出值。
      - 经典的监督学习：分类，回归。
    - Unsupervised Learning: 无监督学习
      - 训练数据无标签
      - 目标：自主发现数据的规律和关系。
      - 经典的无监督学习：聚类。
    - Reinforced Learning: 强化学习
      - 让模型在环境中采取行动，获得结果反馈。在反馈中学习。在给定情况下采取最佳行动，最大化奖励，最消化损失。
  - Deep Learning: 深度学习
    - 不输入监督学习、非监督学习、强化学习的任一类型。是机器学习的一种方法，使用人工神经网络模仿人脑处理信息的方式，通过层次化方法提取和表示数据特征。
    - Generative AI 是深度学习的一种应用。利用神经网络来识别现有内容的模式和结构，学习新的内容。
- LLM: Large Language Model, 大语言模型。
  - 是深度学习的一种应用，专门用于处理自然语言任务。
  - 使用大量文本进行无监督学习。
  - 参数：模型内部的变量。模型在训练过程中得到的知识
    - 参数决定了模型如何对输入数据做出反应，从而决定模型的行为。
    - 参数越多，模型效果越好。

- Not all generative AI is LLM, and Not all LLM is generative AI.

### Transformer
- GPT: Generative Pre-trained Transformer, 生成式，预训练的，Transformer
- RNN: Recurrent Neural Network, 循环神经网络。
  - 在Transformer出现前，人工智能主要使用RNN来完成。
  - RNN按顺序逐字处理，1. 无法并行训练，效率低。2.不善长文本。
  - LSTM,长短期记忆网络，用于长文本优化方案。
- Transformer: 
  - 两大核心：自注意力机制，位置编码。
  - 运行机制：
    - 将字转换为向量，使用token来表示。包括词的向量表示+词位置的向量表示。
    - 将字词的向量值传给模型。模型有词+位置的数据，则可以进行并行处理。

### Transformer架构逻辑
- Transformer架构分为编码器encoder和解码器decoder两大部分。encoder接收输入，decoder输出结果。
- 工作过程：
  1. 接收原始文本，将文本进行token化转化为数字。再用数字形式的Token ID表示token以存储文本。
     - token是文本的一个基本单位，有较多的方式实现。一个词可能用一个或多个token表示。
  2. 将token ID传入嵌入层input embedding。让每个token都用向量表示。
     - 向量可以看做是一堆数字，多维度表示词的语法及语义。相近的数字差值越小。在空间中就越接近。
     - 所以向量不仅可以帮助模型理解词的语义，还能捕捉词与词之间的关系。
  3. 对向量进行位置编码，positional encoding。将词的位置信息用数字表示，加入到向量中。
  4. 编码过程：将向量传入编码器，转为更抽象的向量形式，保留词的语法语义特征及位置信信息。输出包含词本身信息加上上下文相关信息。
     - 编码器的核心：自注意力机制（Attention）。通过计算每个词之间的相关性来决定注意力权重，相关性越强，注意力权重越高。
     - Transformer使用多头自注意力，一个编码器包含多个自注意力模块。每个模块有自己的关注点，并行计算，互不影响。
     - 将自注意力模块的输出传递给前馈神经网络（Feed Forward）进一步处理。
     - 多个编码器可以进行堆叠。
  5. 解码器部分接收数据：
     - 先接收一个特殊值表示序列开头。
     - 接收编码器的输出。
     - 接收解码器之前已经输出的数据。
       - 因为解码器输入包括编码器的出和解码器之前的输出，所以需要一个开头标志以保障输出连贯性和上下文相关性。
  6. 解码过程：与编码过程较为类似。
     1. 对已输出文本进行嵌入。
     2. 对已输出文本进行位置编码。
     3. 进入针对已生成的输出序列的带掩码的多头注意力模块。此时只会关注本词和本词前的其他词，不会关注本词后面的内容，以保障解码器生成文本时遵循正确的时间顺序。
     4. 进入针对输入序列抽象表示的多头自注意力模块。此时捕捉编码器的输入和即将生成的输出之间的关系，将原始输入序列信息与输出融合。
     5. 将输出传递给前馈神经网络，计算增强模型表达能力。
     - 多个解码器可以进行堆叠。
  7. 线性层 linear 和 Softmax层。
     - 将解码器输出转化为词汇表的概率分布，用词汇表的概率分布代表下一个被生成的Token的概率。选择高概率的座位下一个输出。
     - 本质是猜测下一个输出。输出是否正确，模型不知道。所以会有错误的回答，这叫幻觉Hallucination.
  8. 重复输出，直到得到表示结束的Token

### Transformer的三种形式
- 仅编码器 Encoder-Only
  - 又叫自编码器模型，Autoencoding model
  - 只保留了编码器部分。
  - 例子：BERT
  - 用例：掩码语言建模，情感分析
- 仅解码器 Decoder-Only
  - 又叫自回归模型，Autoregressive model
  - 只保留了解码器部分
  - 例子：GPT-2， GPT-3
  - 用例：文本生成
- 编码器-解码器 encoder-decoder
  - 又叫序列到序列模型， Sequence-to-sequence model
  - 既有编码器，又有解码器
  - 例子：T5， BART
  - 用例：翻译，总结

### ChatGPT建立过程
1. 无监督学习
   - 通过大量文本进行无监督学习，预训练得到一个能进行文本生成的基座模型。
   - GPT模型先看到一部分文本，然后预测下一个token，比较正确答案和它的预测来更新权重，逐步优化。
   - 此时还不能对话，只能根据上下文继续生成相似文本。不能回答问题。
2. 监督微调
   - 通过人类撰写的高质量文本对基座模型进行监督学习微调，通过改变参数得到更加适应特定任务的微调后的基座模型。SFT模型（Supervised Fine-Tuning）
   - 微调所需要的数据，时间都更少，所以成本也更低。
3. 训练奖励模型+强化学习训练
   - 模型对问题回答出多个对应的答案。让人类对回答质量进行打分排序，基于数据训练出一个能对回答进行评分预测的奖励模型。
   - 让第二步的模型对问题生成回答，用奖励模型给回答评分，利用评分进行反馈，从而完成强化学习训练。
   - 人类打分原则为 3H原则
     - Helpful 有用性，判断模型遵循用户指令以及推断指令的能力。
     - Honest 真实性，判断模型产生幻觉（编造事实）的倾向。
     - Harmless 无害性，判断模型的输出是否适当，是否诋毁或包含贬义内容。

### 提示词工程 Prompt Engineering
- Prompt Engineering 研究如何提高和AI的沟通质量及效率。
- 核心关注提示的开发和优化。
- AI不知道自己不知道的知识，只会根据已有的知识来预测下一个token，并根据概率给出答案。所以它会一本正经的胡说八道。

- 几个应用
  - 小样本提示。
    - 零样本提示：直接问问题或给指令。一般效果不会很好。
    - 给定一些示例，用样本进行引导。AI根据对样本的学习，得到相似的回答。
    - 这种方式还可以让AI自己学习格式，不用另外再给出格式约束。
  - 思维链。
    - 在算式、常识、符号、复杂任务的情况下，小样本提示的方式效果较差。
    - 考虑在提示中不仅给出正确结果，也给出中间推理步骤，AI将过程分解，以提升正确率。
  - 分步骤思考。
    - 不给出样本，但在问题或指令后加上：Let's think step by step，让AI分步骤思考，同样达到小步骤分解，提升正确率的效果。

### RAG 索引增强生成
- RAG: Retrieval Augmented Generation
- 索引增强生成，提供外部文档，AI获取实时且正确的数据，生成可靠的回答。
- 过程：
  1. 将外部文档切分为段落。
  2. 段落转换为向量，存入数据库。
  3. 将问题转换为向量，并在数据库中查找。
  4. 将找到的内容与原问题进行结合，再提交给AI。
  5. AI将外部文档作为上下文进行分析回答。

### PAL 程序辅助语言模型
- PAL: Program-Aided Language Models
- 程序辅助语言模型，AI+程序工具（如Python），不让AI进行计算，让AI生成程序工具的代码，让程序工具进行计算。
- 过程：
  1. 借助思维链，通过小样本提示，给模型示范如何分步骤思考，写出解决问题所需的变量、公式等。
  2. 将用户提问与提示模板进行拼接，给到AI
  3. AI生成代码，给到程序工具，由程序工具进行计算并返回结果。
  4. AI带着结果返回给用户。

### ReAct 推理与行动
- ReAct: Reason(推理) + Action(行动)
- 让模型动态推理，并采取行动与外界环境互动。
- 过程：
  1. 与思维链结合，用小样本提示给模型一个推理与行动的框架。将问题分解为步骤，每个步骤经过推理，行动，观察。
  - 推理：针对问题或上一步观察的思考。
  - 行动：基于推理与外界环境的交互，例如搜索。
  - 观察：对行动得到的结果进行查看。
  2. 通过循环的推理+行动+观察，分步骤得到正确结果。
